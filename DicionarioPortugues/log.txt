WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 83c0721a2c3b5215
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Filtered duplicate request: <GET https://www.merriam-webster.com/dictionary/'fro> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG: Attempting to acquire lock 140154704899632 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140154704899632 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140154704899632 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140154704899632 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'ava> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'avas> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'cause> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'em> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'fro> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'ll> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'re> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'s%20Gravenhage> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'s%20Hertogenbosch> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'t%20Hooft> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'tain't> (referer: None)
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'til> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'tis> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'tude> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'twas> (referer: None)
DEBUG: Crawled (200) <GET https://www.merriam-webster.com/dictionary/'twere> (referer: None)
INFO: Received SIGINT twice, forcing unclean shutdown
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: f28f7090c0df8539
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET https://dicionario.priberam.org/robots.txt> (referer: None)
DEBUG: Attempting to acquire lock 140651924481664 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140651924481664 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140651924481664 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140651924481664 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://dicionario.priberam.org/amar> (referer: None)
DEBUG: Saved file html/amar.html
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 488,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 31584,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.827575,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 7, 7, 4, 937641),
 'httpcompression/response_bytes': 91830,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 8,
 'log_count/INFO': 10,
 'memusage/max': 65880064,
 'memusage/startup': 65880064,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 6, 27, 7, 7, 2, 110066)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 8a11d4ff6ccebd33
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/infopediaSpider.py", line 24, in start_requests
    with open(URLS, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'urls'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.001863,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 13, 52, 14, 748081),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65544192,
 'memusage/startup': 65544192,
 'start_time': datetime.datetime(2022, 6, 27, 13, 52, 14, 746218)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 2f4845c6d9b71be3
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/infopediaSpider.py", line 24, in start_requests
    with open(URLS, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'infopedia/urls'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.00126,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 13, 52, 45, 107921),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65613824,
 'memusage/startup': 65613824,
 'start_time': datetime.datetime(2022, 6, 27, 13, 52, 45, 106661)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 72d53202a10c1e93
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 140022756879440 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140022756879440 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140022756879440 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140022756879440 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.infopedia.pt/robots.txt> (referer: None)
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ABC> (referer: None)
DEBUG: Saved file infopedia/html/ABC
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/AAC?express=AAC> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/AAC>
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ADN> (referer: None)
DEBUG: Saved file infopedia/html/ADN
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/AD> (referer: None)
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/AD>: HTTP status code is not handled or not allowed
INFO: Received SIGINT twice, forcing unclean shutdown
DEBUG: Retrying <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ADSL> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
DEBUG: Retrying <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ACP> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 6ffa2733197b4588
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 140135737769840 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140135737769840 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140135737769840 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140135737769840 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.infopedia.pt/robots.txt> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/AAC?express=AAC> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/AAC>
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/AD> (referer: None)
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/AD>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ABC> (referer: None)
DEBUG: Saved file infopedia/html/ABC
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ADN> (referer: None)
DEBUG: Saved file infopedia/html/ADN
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ACP> (referer: None)
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/ACP>: HTTP status code is not handled or not allowed
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ADSL> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/AML?express=AML> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/AML>
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/ANACOM?express=ANACOM> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ANACOM>
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/ADSL>: HTTP status code is not handled or not allowed
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/AMP> (referer: None)
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/AMP>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/AFP?express=AFP> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/AFP>
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/api-?express=API> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/API>
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/AAC?express=AAC> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/ANC?express=ANC> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ANC>
DEBUG: Saved file infopedia/html/AAC?express=AAC
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/ANMP?express=ANMP> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ANMP>
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/APEL> (referer: None)
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/APPACDM?express=APPACDM> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/APPACDM>
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/APEL>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/APL?express=APL> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/APL>
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/AVC> (referer: None)
DEBUG: Saved file infopedia/html/AVC
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/ANACOM?express=ANACOM> (referer: None)
DEBUG: Saved file infopedia/html/ANACOM?express=ANACOM
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/AML?express=AML> (referer: None)
DEBUG: Saved file infopedia/html/AML?express=AML
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/aacheniano?express=Aachen> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/Aachen>
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/ASCII?express=ASCII> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ASCII>
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/AFP?express=AFP> (referer: None)
DEBUG: Saved file infopedia/html/AFP?express=AFP
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/api-?express=API> (referer: None)
DEBUG: Saved file infopedia/html/api-?express=API
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/ANC?express=ANC> (referer: None)
DEBUG: Saved file infopedia/html/ANC?express=ANC
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/ANMP?express=ANMP> (referer: None)
DEBUG: Saved file infopedia/html/ANMP?express=ANMP
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ASAE> (referer: None)
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/ASAE>: HTTP status code is not handled or not allowed
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/APPACDM?express=APPACDM> (referer: None)
DEBUG: Saved file infopedia/html/APPACDM?express=APPACDM
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/APL?express=APL> (referer: None)
DEBUG: Saved file infopedia/html/APL?express=APL
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/Aarhus> (referer: None)
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/Aarhus>: HTTP status code is not handled or not allowed
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/ARS> (referer: None)
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/Abiss%C3%ADnia> (referer: None)
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/ARS>: HTTP status code is not handled or not allowed
DEBUG: Saved file infopedia/html/Abiss%C3%ADnia
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/Abecassis> (referer: None)
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/Abecassis>: HTTP status code is not handled or not allowed
DEBUG: Redirecting (302) to <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/aboinense?express=Aboim> from <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/Aboim>
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/aacheniano?express=Aachen> (referer: None)
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/Aalborg> (referer: None)
DEBUG: Saved file infopedia/html/aacheniano?express=Aachen
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/Aalborg>: HTTP status code is not handled or not allowed
INFO: Received SIGINT twice, forcing unclean shutdown
WARNING: Got data loss in https://www.infopedia.pt/dicionarios/siglas-abreviaturas/ASCII?express=ASCII. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
DEBUG: Retrying <GET https://www.infopedia.pt/dicionarios/siglas-abreviaturas/ASCII?express=ASCII> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: Chunked decoder in 'BODY' state, still expecting more data to get to 'FINISHED' state.>]
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 192d5d11d4274b4d
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/infopediaSpider.py", line 42, in start_requests
    with open(f'{self.path}/failed.log', 'w') as log:
AttributeError: 'InfopediaSpider' object has no attribute 'path'
DEBUG: Attempting to acquire lock 140374116881488 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140374116881488 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140374116881488 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140374116881488 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.infopedia.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/escrever> (referer: None)
DEBUG: Saved file infopedia/html/escrever
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/verbos-portugueses/escrever> (referer: https://www.infopedia.pt/dicionarios/lingua-portuguesa/escrever)
ERROR: Spider error processing <GET https://www.infopedia.pt/dicionarios/verbos-portugueses/escrever> (referer: https://www.infopedia.pt/dicionarios/lingua-portuguesa/escrever)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/infopediaSpider.py", line 61, in get_conj
    with open(filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'infopedia/html_conj/escrever'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1175,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 55560,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 4.381775,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 14, 4, 56, 356431),
 'httpcompression/response_bytes': 195435,
 'httpcompression/response_count': 3,
 'log_count/DEBUG': 9,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'memusage/max': 65683456,
 'memusage/startup': 65683456,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/FileNotFoundError': 1,
 'start_time': datetime.datetime(2022, 6, 27, 14, 4, 51, 974656)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 345eaf862e63729a
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/infopediaSpider.py", line 44, in start_requests
    with open(f'{self.path}/failed.log', 'w') as log:
AttributeError: 'InfopediaSpider' object has no attribute 'path'
DEBUG: Attempting to acquire lock 140676983364944 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140676983364944 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140676983364944 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140676983364944 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.infopedia.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/escrever> (referer: None)
DEBUG: Saved file infopedia/html/escrever
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/verbos-portugueses/escrever> (referer: https://www.infopedia.pt/dicionarios/lingua-portuguesa/escrever)
DEBUG: Saved file infopedia/conj/escrever
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1175,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 55445,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 3.658502,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 14, 7, 2, 407707),
 'httpcompression/response_bytes': 195419,
 'httpcompression/response_count': 3,
 'log_count/DEBUG': 10,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65736704,
 'memusage/startup': 65736704,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 6, 27, 14, 6, 58, 749205)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: df1826cc070080da
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 140584182880896 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140584182880896 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140584182880896 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140584182880896 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.infopedia.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/escrever> (referer: None)
DEBUG: Saved file infopedia/html/escrever
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/verbos-portugueses/escrever> (referer: https://www.infopedia.pt/dicionarios/lingua-portuguesa/escrever)
DEBUG: Saved file infopedia/conj/escrever
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1175,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 55400,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 4.607179,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 14, 7, 51, 776718),
 'httpcompression/response_bytes': 195474,
 'httpcompression/response_count': 3,
 'log_count/DEBUG': 10,
 'log_count/INFO': 10,
 'memusage/max': 65683456,
 'memusage/startup': 65683456,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 6, 27, 14, 7, 47, 169539)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: a78a3225aa6dd06f
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 139725730961808 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 139725730961808 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 139725730961808 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 139725730961808 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.infopedia.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/amas> (referer: None)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 631,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 27241,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.838673,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 17, 52, 58, 514023),
 'httpcompression/response_bytes': 88609,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 7,
 'log_count/INFO': 10,
 'memusage/max': 65683456,
 'memusage/startup': 65683456,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 6, 27, 17, 52, 55, 675350)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: aa725eb78c8468bc
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 140552793758480 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140552793758480 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140552793758480 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140552793758480 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.infopedia.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/amas> (referer: None)
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 631,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 27249,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 4.728858,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 17, 54, 14, 92366),
 'httpcompression/response_bytes': 88628,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 7,
 'log_count/INFO': 10,
 'memusage/max': 65732608,
 'memusage/startup': 65732608,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 6, 27, 17, 54, 9, 363508)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: aea91eae50233828
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 140135165089472 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140135165089472 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140135165089472 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140135165089472 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.infopedia.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/amar> (referer: None)
DEBUG: Saved file infopedia/html/amar
DEBUG: Crawled (200) <GET https://www.infopedia.pt/dicionarios/verbos-portugueses/amar> (referer: https://www.infopedia.pt/dicionarios/lingua-portuguesa/amar)
DEBUG: Saved file infopedia/conj/amar
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1163,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 55606,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 4.104103,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 17, 54, 29, 759174),
 'httpcompression/response_bytes': 196022,
 'httpcompression/response_count': 3,
 'log_count/DEBUG': 10,
 'log_count/INFO': 10,
 'memusage/max': 65855488,
 'memusage/startup': 65855488,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 6, 27, 17, 54, 25, 655071)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 9a194cfe4bed00e1
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Attempting to acquire lock 140371606101328 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140371606101328 acquired on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Attempting to release lock 140371606101328 on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Lock 140371606101328 released on /home/ferris/.cache/python-tldextract/3.10.5.final__usr__7d8fdf__tldextract-3.3.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG: Crawled (200) <GET https://www.infopedia.pt/robots.txt> (referer: None)
DEBUG: Crawled (404) <GET https://www.infopedia.pt/dicionarios/lingua-portuguesa/uioashfioaushfoaisudf> (referer: None)
INFO: Ignoring response <404 https://www.infopedia.pt/dicionarios/lingua-portuguesa/uioashfioaushfoaisudf>: HTTP status code is not handled or not allowed
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 648,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 24514,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 4.644331,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 27, 17, 54, 53, 827117),
 'httpcompression/response_bytes': 75295,
 'httpcompression/response_count': 2,
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 7,
 'log_count/INFO': 11,
 'memusage/max': 65630208,
 'memusage/startup': 65630208,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 6, 27, 17, 54, 49, 182786)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 75c7bdc0ccc3e575
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET https://www.lexico.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml> (referer: None)
ERROR: Spider error processing <GET https://www.lexico.pt/sitemap.xml> (referer: None)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 57, in _parse_sitemap
    if any(x.search(loc) for x in self._follow):
AttributeError: 'MySpider' object has no attribute '_follow'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 475,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1244,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.062475,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 6, 28, 11, 44, 35, 487186),
 'httpcompression/response_bytes': 2490,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65433600,
 'memusage/startup': 65433600,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2022, 6, 28, 11, 44, 33, 424711)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 117da0529c1add77
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(self)
TypeError: descriptor '__init__' requires a 'super' object but received a 'LexicoSpider'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(self)
TypeError: descriptor '__init__' requires a 'super' object but received a 'LexicoSpider'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(self)
TypeError: descriptor '__init__' requires a 'super' object but received a 'LexicoSpider'
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 133c9de00ff8838e
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(SitemapSpider, self)
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(SitemapSpider, self)
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(SitemapSpider, self)
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 065d5a6cb37ffdab
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(super)
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(super)
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(super)
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 757344daa660fe4a
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(SitemapSpider. self).__init__()
AttributeError: type object 'SitemapSpider' has no attribute 'self'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(SitemapSpider. self).__init__()
AttributeError: type object 'SitemapSpider' has no attribute 'self'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(SitemapSpider. self).__init__()
AttributeError: type object 'SitemapSpider' has no attribute 'self'
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: b16a75129903feaa
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(SitemapSpider, self).__init__()
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(SitemapSpider, self).__init__()
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(SitemapSpider, self).__init__()
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: fbd73272c45a3f00
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(LexicoSpider, self).__init__()
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(LexicoSpider, self).__init__()
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(LexicoSpider, self).__init__()
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: f326d2bbd0b59de1
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: Unhandled error in Deferred:
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(super, self).__init__()
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(super, self).__init__()
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
CRITICAL: 
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 101, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/crawler.py", line 113, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/__init__.py", line 48, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 14, in __init__
    super.__init__(super, self).__init__()
TypeError: descriptor '__init__' requires a 'super' object but received a 'type'
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 1c771e05b6ddc5c9
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET https://www.lexico.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml> (referer: None)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=35> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=34> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=33> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=31> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=32> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=29> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=30> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=28> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=27> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=26> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=25> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=24> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=23> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=22> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=21> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=20> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/vimba/> (referer: https://www.lexico.pt/sitemap.xml?p=35)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=19> (referer: https://www.lexico.pt/sitemap.xml)
ERROR: Spider error processing <GET https://www.lexico.pt/vimba/> (referer: https://www.lexico.pt/sitemap.xml?p=35)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">vimba</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/vacilacao/> (referer: https://www.lexico.pt/sitemap.xml?p=34)
ERROR: Spider error processing <GET https://www.lexico.pt/vacilacao/> (referer: https://www.lexico.pt/sitemap.xml?p=34)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">vacilao</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/tinturao/> (referer: https://www.lexico.pt/sitemap.xml?p=33)
DEBUG: Crawled (200) <GET https://www.lexico.pt/tintura/> (referer: https://www.lexico.pt/sitemap.xml?p=33)
ERROR: Spider error processing <GET https://www.lexico.pt/tinturao/> (referer: https://www.lexico.pt/sitemap.xml?p=33)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">tinturo</h1>\'>].html'
ERROR: Spider error processing <GET https://www.lexico.pt/tintura/> (referer: https://www.lexico.pt/sitemap.xml?p=33)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">tintura</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/sovelar/> (referer: https://www.lexico.pt/sitemap.xml?p=32)
ERROR: Spider error processing <GET https://www.lexico.pt/sovelar/> (referer: https://www.lexico.pt/sitemap.xml?p=32)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">sovelar</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/propositadamente/> (referer: https://www.lexico.pt/sitemap.xml?p=29)
ERROR: Spider error processing <GET https://www.lexico.pt/propositadamente/> (referer: https://www.lexico.pt/sitemap.xml?p=29)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">propositadamente</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/relengo/> (referer: https://www.lexico.pt/sitemap.xml?p=30)
ERROR: Spider error processing <GET https://www.lexico.pt/relengo/> (referer: https://www.lexico.pt/sitemap.xml?p=30)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">relengo</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/picotilho/> (referer: https://www.lexico.pt/sitemap.xml?p=28)
ERROR: Spider error processing <GET https://www.lexico.pt/picotilho/> (referer: https://www.lexico.pt/sitemap.xml?p=28)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">picotilho</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/parchear/> (referer: https://www.lexico.pt/sitemap.xml?p=27)
ERROR: Spider error processing <GET https://www.lexico.pt/parchear/> (referer: https://www.lexico.pt/sitemap.xml?p=27)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">parchear</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/mosquitar/> (referer: https://www.lexico.pt/sitemap.xml?p=25)
ERROR: Spider error processing <GET https://www.lexico.pt/mosquitar/> (referer: https://www.lexico.pt/sitemap.xml?p=25)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">mosquitar</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/oligarquico/> (referer: https://www.lexico.pt/sitemap.xml?p=26)
ERROR: Spider error processing <GET https://www.lexico.pt/oligarquico/> (referer: https://www.lexico.pt/sitemap.xml?p=26)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">oligrquico</h1>\'>].html'
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
DEBUG: Crawled (200) <GET https://www.lexico.pt/mesossemo/> (referer: https://www.lexico.pt/sitemap.xml?p=24)
ERROR: Spider error processing <GET https://www.lexico.pt/mesossemo/> (referer: https://www.lexico.pt/sitemap.xml?p=24)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">mesossemo</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/malabar/> (referer: https://www.lexico.pt/sitemap.xml?p=23)
ERROR: Spider error processing <GET https://www.lexico.pt/malabar/> (referer: https://www.lexico.pt/sitemap.xml?p=23)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">malabar</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/lassitude/> (referer: https://www.lexico.pt/sitemap.xml?p=22)
DEBUG: Crawled (200) <GET https://www.lexico.pt/ingluvioso/> (referer: https://www.lexico.pt/sitemap.xml?p=21)
ERROR: Spider error processing <GET https://www.lexico.pt/lassitude/> (referer: https://www.lexico.pt/sitemap.xml?p=22)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">lassitude</h1>\'>].html'
ERROR: Spider error processing <GET https://www.lexico.pt/ingluvioso/> (referer: https://www.lexico.pt/sitemap.xml?p=21)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">ingluvioso</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/hemoplania/> (referer: https://www.lexico.pt/sitemap.xml?p=20)
ERROR: Spider error processing <GET https://www.lexico.pt/hemoplania/> (referer: https://www.lexico.pt/sitemap.xml?p=20)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">hemoplania</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/hemopatologia/> (referer: https://www.lexico.pt/sitemap.xml?p=20)
ERROR: Spider error processing <GET https://www.lexico.pt/hemopatologia/> (referer: https://www.lexico.pt/sitemap.xml?p=20)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">hemopatologia</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargalhar/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/gargalhar/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">gargalhar</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargalhadear/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/gargalhadear/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">gargalhadear</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargaleiro/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/gargaleiro/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">gargaleiro</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargalacar/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/gargalacar/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">gargalaar</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargal/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/gargal/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">gargal</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargajola/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/gargajola/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">gargajola</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargacalada/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/gargacalada/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">gargaalada</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/garfuana/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/garfuana/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">garfuana</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/garfilha/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/garfilha/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">garfilha</h1>\'>].html'
DEBUG: Crawled (200) <GET https://www.lexico.pt/garfete/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
ERROR: Spider error processing <GET https://www.lexico.pt/garfete/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 25, in parse
    with open(html, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'lexico/html/[<Selector xpath="//h1[@class=\'title\']" data=\'<h1 class="title">garfete</h1>\'>].html'
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 13077,
 'downloader/request_count': 46,
 'downloader/request_method_count/GET': 46,
 'downloader/response_bytes': 356614,
 'downloader/response_count': 46,
 'downloader/response_status_count/200': 46,
 'elapsed_time_seconds': 33.820215,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2022, 6, 28, 12, 2, 41, 333008),
 'httpcompression/response_bytes': 2492208,
 'httpcompression/response_count': 45,
 'log_count/DEBUG': 47,
 'log_count/ERROR': 27,
 'log_count/INFO': 11,
 'memusage/max': 65716224,
 'memusage/startup': 65716224,
 'request_depth_max': 2,
 'response_received_count': 46,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 45,
 'scheduler/dequeued/memory': 45,
 'scheduler/enqueued': 32950,
 'scheduler/enqueued/memory': 32950,
 'spider_exceptions/FileNotFoundError': 27,
 'start_time': datetime.datetime(2022, 6, 28, 12, 2, 7, 512793)}
INFO: Spider closed (shutdown)
INFO: Error while scheduling new request
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/engine.py", line 187, in <lambda>
    d.addBoth(lambda _: self.slot.nextcall.schedule())
AttributeError: 'NoneType' object has no attribute 'nextcall'
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 3ad95aeba2fad498
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
DEBUG: Crawled (200) <GET https://www.lexico.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml> (referer: None)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 475,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1244,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 13.37688,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2022, 6, 28, 12, 3, 25, 782904),
 'httpcompression/response_bytes': 2490,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 3,
 'log_count/INFO': 11,
 'memusage/max': 65605632,
 'memusage/startup': 65605632,
 'request_depth_max': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 36,
 'scheduler/enqueued/memory': 36,
 'start_time': datetime.datetime(2022, 6, 28, 12, 3, 12, 406024)}
INFO: Spider closed (shutdown)
INFO: Error while scheduling new request
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/task.py", line 526, in _oneWorkUnit
    result = next(self._iterator)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/engine.py", line 187, in <lambda>
    d.addBoth(lambda _: self.slot.nextcall.schedule())
AttributeError: 'NoneType' object has no attribute 'nextcall'
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: f421b3d8c0b7eb1c
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET https://www.lexico.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml> (referer: None)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=35> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=34> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=33> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=32> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=31> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=30> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=29> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=28> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=26> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=25> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=24> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=23> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=22> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=20> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=21> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=19> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/vimba/> (referer: https://www.lexico.pt/sitemap.xml?p=35)
ERROR: Spider error processing <GET https://www.lexico.pt/vimba/> (referer: https://www.lexico.pt/sitemap.xml?p=35)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/vacilacao/> (referer: https://www.lexico.pt/sitemap.xml?p=34)
ERROR: Spider error processing <GET https://www.lexico.pt/vacilacao/> (referer: https://www.lexico.pt/sitemap.xml?p=34)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/tinturao/> (referer: https://www.lexico.pt/sitemap.xml?p=33)
ERROR: Spider error processing <GET https://www.lexico.pt/tinturao/> (referer: https://www.lexico.pt/sitemap.xml?p=33)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/sovelar/> (referer: https://www.lexico.pt/sitemap.xml?p=32)
ERROR: Spider error processing <GET https://www.lexico.pt/sovelar/> (referer: https://www.lexico.pt/sitemap.xml?p=32)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/sarrafacadura/> (referer: https://www.lexico.pt/sitemap.xml?p=31)
ERROR: Spider error processing <GET https://www.lexico.pt/sarrafacadura/> (referer: https://www.lexico.pt/sitemap.xml?p=31)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/respo/> (referer: https://www.lexico.pt/sitemap.xml?p=30)
ERROR: Spider error processing <GET https://www.lexico.pt/respo/> (referer: https://www.lexico.pt/sitemap.xml?p=30)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/prurigem/> (referer: https://www.lexico.pt/sitemap.xml?p=29)
ERROR: Spider error processing <GET https://www.lexico.pt/prurigem/> (referer: https://www.lexico.pt/sitemap.xml?p=29)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/picotilho/> (referer: https://www.lexico.pt/sitemap.xml?p=28)
ERROR: Spider error processing <GET https://www.lexico.pt/picotilho/> (referer: https://www.lexico.pt/sitemap.xml?p=28)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/oligarquico/> (referer: https://www.lexico.pt/sitemap.xml?p=26)
ERROR: Spider error processing <GET https://www.lexico.pt/oligarquico/> (referer: https://www.lexico.pt/sitemap.xml?p=26)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
DEBUG: Crawled (200) <GET https://www.lexico.pt/munguengue/> (referer: https://www.lexico.pt/sitemap.xml?p=25)
ERROR: Spider error processing <GET https://www.lexico.pt/munguengue/> (referer: https://www.lexico.pt/sitemap.xml?p=25)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/mesossemo/> (referer: https://www.lexico.pt/sitemap.xml?p=24)
ERROR: Spider error processing <GET https://www.lexico.pt/mesossemo/> (referer: https://www.lexico.pt/sitemap.xml?p=24)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/malabar/> (referer: https://www.lexico.pt/sitemap.xml?p=23)
ERROR: Spider error processing <GET https://www.lexico.pt/malabar/> (referer: https://www.lexico.pt/sitemap.xml?p=23)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
DEBUG: Crawled (200) <GET https://www.lexico.pt/lassitude/> (referer: https://www.lexico.pt/sitemap.xml?p=22)
ERROR: Spider error processing <GET https://www.lexico.pt/lassitude/> (referer: https://www.lexico.pt/sitemap.xml?p=22)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/home/ferris/projects/DicionarioPt/Pycharm/DicionarioPortugues/DicionarioPortugues/spiders/LexicoSpider.py", line 26, in parse
    f.write(main_content)
TypeError: a bytes-like object is required, not 'SelectorList'
INFO: Received SIGINT twice, forcing unclean shutdown
DEBUG: Retrying <GET https://www.lexico.pt/sitemap.xml?p=27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.8.0.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Jun  6 2022, 18:49:26) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1p  21 Jun 2022), cryptography 37.0.2, Platform Linux-5.18.7-arch1-1-x86_64-with-glibc2.35
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 8181235a45dc3ce1
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET https://www.lexico.pt/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml> (referer: None)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=35> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=34> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=31> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=30> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=29> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=28> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=27> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=32> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=33> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=25> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=24> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=26> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=21> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=20> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=23> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=22> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sitemap.xml?p=19> (referer: https://www.lexico.pt/sitemap.xml)
DEBUG: Crawled (200) <GET https://www.lexico.pt/vacilacao/> (referer: https://www.lexico.pt/sitemap.xml?p=34)
DEBUG: Crawled (200) <GET https://www.lexico.pt/salinometro/> (referer: https://www.lexico.pt/sitemap.xml?p=31)
DEBUG: Crawled (200) <GET https://www.lexico.pt/respo/> (referer: https://www.lexico.pt/sitemap.xml?p=30)
DEBUG: Crawled (200) <GET https://www.lexico.pt/pouquidao/> (referer: https://www.lexico.pt/sitemap.xml?p=29)
DEBUG: Crawled (200) <GET https://www.lexico.pt/picheiro/> (referer: https://www.lexico.pt/sitemap.xml?p=28)
DEBUG: Crawled (200) <GET https://www.lexico.pt/sovelar/> (referer: https://www.lexico.pt/sitemap.xml?p=32)
DEBUG: Crawled (200) <GET https://www.lexico.pt/tintura/> (referer: https://www.lexico.pt/sitemap.xml?p=33)
DEBUG: Crawled (200) <GET https://www.lexico.pt/mesossemo/> (referer: https://www.lexico.pt/sitemap.xml?p=24)
DEBUG: Crawled (200) <GET https://www.lexico.pt/oligarquico/> (referer: https://www.lexico.pt/sitemap.xml?p=26)
DEBUG: Crawled (200) <GET https://www.lexico.pt/ingluvioso/> (referer: https://www.lexico.pt/sitemap.xml?p=21)
DEBUG: Crawled (200) <GET https://www.lexico.pt/ingluvial/> (referer: https://www.lexico.pt/sitemap.xml?p=21)
DEBUG: Crawled (200) <GET https://www.lexico.pt/parchear/> (referer: https://www.lexico.pt/sitemap.xml?p=27)
DEBUG: Crawled (200) <GET https://www.lexico.pt/tinturao/> (referer: https://www.lexico.pt/sitemap.xml?p=33)
DEBUG: Crawled (200) <GET https://www.lexico.pt/machucar/> (referer: https://www.lexico.pt/sitemap.xml?p=23)
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargalhar/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargalhadear/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargaleiro/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/malabar/> (referer: https://www.lexico.pt/sitemap.xml?p=23)
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargal/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargalacar/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargajola/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
INFO: Received SIGINT, shutting down gracefully. Send again to force 
INFO: Closing spider (shutdown)
DEBUG: Crawled (200) <GET https://www.lexico.pt/gargacalada/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/garfuana/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/garfete/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/garfilha/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/garfejar/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
DEBUG: Crawled (200) <GET https://www.lexico.pt/garfar/> (referer: https://www.lexico.pt/sitemap.xml?p=19)
INFO: Received SIGINT twice, forcing unclean shutdown
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Aug  1 2022, 07:53:20) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1q  5 Jul 2022), cryptography 37.0.4, Platform Linux-5.18.16-arch1-1-x86_64-with-glibc2.36
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: 1b10088b35be4e16
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemap.xml> (referer: None)
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.8.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.8.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.6.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.6.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.5.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.5.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.7.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.7.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.3.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.3.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.4.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.4.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.2.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.2.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/word.3.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.1.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/word.3.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.1.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/word.2.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/word.2.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/word.1.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/word.1.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3971,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 2199306,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 11.864132,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 8, 8, 8, 17, 26, 757730),
 'httpcompression/response_bytes': 1624,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 14,
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'memusage/max': 65708032,
 'memusage/startup': 65708032,
 'request_depth_max': 1,
 'response_received_count': 13,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/AttributeError': 11,
 'start_time': datetime.datetime(2022, 8, 8, 8, 17, 14, 893598)}
INFO: Spider closed (finished)
WARNING: /home/ferris/.local/lib/python3.10/site-packages/scrapy/spiderloader.py:37: UserWarning: There are several spiders with the same name:

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.GrSpider)

  MauroSpider named 'repubblica' (in DicionarioPortugues.spiders.RepubblicaSpider)

  This can cause unexpected behavior.
  warnings.warn(

INFO: Scrapy 2.6.1 started (bot: DicionarioPortugues)
INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.10.5 (main, Aug  1 2022, 07:53:20) [GCC 12.1.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1q  5 Jul 2022), cryptography 37.0.4, Platform Linux-5.18.16-arch1-1-x86_64-with-glibc2.36
INFO: Overridden settings:
{'BOT_NAME': 'DicionarioPortugues',
 'DOWNLOAD_DELAY': 0.5,
 'NEWSPIDER_MODULE': 'DicionarioPortugues.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['DicionarioPortugues.spiders'],
 'USER_AGENT': 'DicionarioPortugues (+http://www.yourdomain.com)'}
DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
INFO: Telnet Password: efec847e71053073
INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO: Enabled item pipelines:
[]
INFO: Spider opened
INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO: Telnet console listening on 127.0.0.1:6023
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/robots.txt> (referer: None)
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemap.xml> (referer: None)
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.8.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.8.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.7.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.7.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.6.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.6.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.5.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.5.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.4.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.3.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.4.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.3.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.2.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.2.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/incorrect.1.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/incorrect.1.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/word.3.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/word.3.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/word.2.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/word.2.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
DEBUG: Crawled (200) <GET http://rechnik.chitanka.info/sitemaps/word.1.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
ERROR: Spider error processing <GET http://rechnik.chitanka.info/sitemaps/word.1.txt.gz> (referer: http://rechnik.chitanka.info/sitemap.xml)
Traceback (most recent call last):
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/spiders/sitemap.py", line 52, in _parse_sitemap
    s = Sitemap(body)
  File "/home/ferris/.local/lib/python3.10/site-packages/scrapy/utils/sitemap.py", line 20, in __init__
    rt = self._root.tag
AttributeError: 'NoneType' object has no attribute 'tag'
INFO: Closing spider (finished)
INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3971,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 2199330,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 12.206928,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 8, 8, 8, 18, 57, 791450),
 'httpcompression/response_bytes': 1624,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 14,
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'memusage/max': 65765376,
 'memusage/startup': 65765376,
 'request_depth_max': 1,
 'response_received_count': 13,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/AttributeError': 11,
 'start_time': datetime.datetime(2022, 8, 8, 8, 18, 45, 584522)}
INFO: Spider closed (finished)
